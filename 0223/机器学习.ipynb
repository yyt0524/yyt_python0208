{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ead2fd4",
   "metadata": {},
   "source": [
    "## 人工智能和机器学习概述\n",
    "\n",
    "所谓“人工智能”通常是泛指让机器具有像人一样的智慧的技术，其目的是让机器像人一样能够感知、思考和解决问题；而“机器学习”通常是指让计算机通过学习现有的数据，实现认知的更新和进步。显然，机器学习是实现人工智能的一种途径，这也是我们的课程要讨论的内容。现如今，“机器学习”和“大数据”可以说是最时髦的两个词汇，而在弱人工智能阶段，无论是“机器学习”还是“大数据”最终要解决的问题本质上是一样的，就是让计算机将纷繁复杂的数据处理成有用的信息，这样就可以发掘出数据带来的意义以及隐藏在数据背后的规律，简单的说就是用现有的数据对将来的状况做出预测和判断。\n",
    "\n",
    "在讨论机器学习相关内容之前，我们先按照问题的“输入”和“输出”对用计算机求解的问题进行一个分类，如下所示：\n",
    "\n",
    "1. 输入的信息是精确的，要求输出最优解。\n",
    "2. 输入的信息是精确的，无法找到最优解，只能获得满意解。\n",
    "3. 输入的信息是模糊的，要求输出最优解。\n",
    "4. 输入的信息是模糊的，无法找到最优解，只能获得满意解。\n",
    "\n",
    "在上面的四大类问题中，第1类问题是计算机最擅长解决的，这类问题其实就是“数值计算”和“逻辑推理”方面的问题，而传统意义上的人工智能也就是利用逻辑推理来解决问题（如早期的“人机对弈”）。一直以来，我们都习惯于将计算机称为“电脑”，而基于“冯诺依曼”体系结构的“电脑”实际上只是实现了“人脑”理性思维这部分的功能，而且在这一点上“电脑”的表现通常是优于“人脑”的；但是“人脑”在处理模糊输入信息时表现出来的强大处理能力，在很多场景下“电脑”是难以企及的。所以我们研究机器学习的算法，就是要解决在输入模糊信息时让计算机给出满意解甚至是最优解的问题。\n",
    "\n",
    "人类通过记忆和归纳这两种方式进行学习，通过记忆可以积累单个事实，使用归纳可以从旧的事实推导出新的事实。所以机器学习其实是一种训练，让计算机通过这种训练能够学会根据数据隐含模式进行合理推断的能力，其基本流程如下所示：\n",
    "\n",
    "1. 观察一组实例，通常称为训练数据，它们可以表示某种统计现象的不完整信息;\n",
    "2. 对观测到的实例进行扩展，并使用推断技术对扩展过程建模;\n",
    "3. 使用这个模型对未知实例进行预测。\n",
    "\n",
    "### 基本概念\n",
    "\n",
    "#### 监督学习和非监督学习\n",
    "\n",
    "监督学习是从给定的训练数据集中学习得到一个函数，当新的数据到来时，可以根据这个函数预测结果，监督学习的训练集包括输入和输出，也可以说是特征和目标。监督学习的目标是由人来标注的，而非监督学习的数据没有类别信息，训练集也没有人为标注结果，通过无监督学习可以减少数据特征的维度，以便我们可以使用二维或三维图形更加直观地展示数据中的信息 。\n",
    "\n",
    "#### 特征向量和特征工程\n",
    "\n",
    "\n",
    "\n",
    "#### 距离度量\n",
    "\n",
    "\n",
    "\n",
    "1. 欧氏距离\n",
    "\n",
    "$$\n",
    "d = \\sqrt{\\sum_{k=1}^n(x_{1k}-x_{2k})^2}\n",
    "$$\n",
    "\n",
    "2. 曼哈顿距离\n",
    "\n",
    "$$\n",
    "d = \\sum_{k=1}^n \\mid {x_{1k}-x_{2k}} \\mid\n",
    "$$\n",
    "\n",
    "3. 切比雪夫距离\n",
    "\n",
    "$$\n",
    "d = max(\\mid x_{1k}-x_{2k} \\mid)\n",
    "$$\n",
    "\n",
    "4. 闵可夫斯基距离\n",
    "    - 当$p=1$时，就是曼哈顿距离\n",
    "    - 当$p=2$时，就是欧式距离\n",
    "    - 当$p \\to \\infty$时，就是切比雪夫距离\n",
    "\n",
    "$$\n",
    "d = \\sqrt[p]{\\sum_{k=1}^n \\mid x_{1k}-x_{2k} \\mid ^p}\n",
    "$$\n",
    "\n",
    "5. 余弦距离\n",
    "    $$\n",
    "    cos(\\theta) = \\frac{\\sum_{k=1}^n x_{1k}x_{2k}}{\\sqrt{\\sum_{k=1}^n x_{1k}^2} \\sqrt{\\sum_{k=1}^n x_{2k}^2}}\n",
    "    $$\n",
    "\n",
    "### 机器学习的定义和应用领域\n",
    "\n",
    "根据上面的论述，我们可以给“机器学习”下一个正式的定义：**机器学习是一门专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身性能的学科**。即使对于机器学习这个概念不那么熟悉，但是机器学习的成果已经广泛渗透到了生产生活的各个领域，下面的这些场景对于你来说一定不陌生。\n",
    "\n",
    "场景1：搜索引擎会根据搜索和使用习惯，优化下一次搜索的结果。\n",
    "\n",
    "场景2：电商网站会根据你的访问历史自动推荐你可能感兴趣的商品。\n",
    "\n",
    "场景3：金融类产品会通过你最近的金融活动信息综合评定你的贷款申请。\n",
    "\n",
    "场景4：视频和直播平台会自动识别图片和视频中有没有不和谐的内容。\n",
    "\n",
    "场景5：智能家电和智能汽车会根据你的语音指令做出相应的动作。\n",
    "\n",
    "简单的总结一下，机器学习可以应用到但不限于以下领域：\n",
    "\n",
    "1. 计算机视觉。计算机视觉是指机器感知环境的能力，目前在[**物体检测**](https://pjreddie.com/darknet/yolo/)和**人脸识别**这两个领域已经非常成熟且产生了大量的应用。\n",
    "\n",
    "    - 刷脸支付\n",
    "\n",
    "        ![](res/face_paying.png)\n",
    "\n",
    "    - [涂鸦识别](https://quickdraw.withgoogle.com/)\n",
    "\n",
    "        ![](res/quickdraw.png)\n",
    "\n",
    "2. 自然语言处理（NLP）。自然语言处理是目前机器学习中一个非常热门的分支，具体的又可以分为三类应用场景。其中文本挖掘主要是对文本进行分类，包括句法分析、情绪分析和垃圾信息检测等；而机器翻译和语音识别相信不用太多的解释大家也都清楚。\n",
    "\n",
    "    - 文本挖掘\n",
    "    - 机器翻译\n",
    "\n",
    "    - 语音识别\n",
    "\n",
    "        ![](res/xiaomi_ai_voice_box.png)\n",
    "\n",
    "3. 机器人。机器人可以分为固定机器人和移动机器人两大类。固定机器人通常被用于工业生产，例如用于装配流水线。常见的移动机器人应用有货运机器人、空中机器人和自动载具。机器人需要软硬件的协作才能实现最优的作业，其中硬件包含传感器、反应器和控制器等，而软件主要是实现感知能力，包括定位、测绘、目标检测和识别等。\n",
    "\n",
    "    - 机甲大师\n",
    "\n",
    "        ![](res/dajiang_robomaster.png)\n",
    "\n",
    "    - 扫地机器人\n",
    "\n",
    "        ![](res/sweep_robot.jpg)\n",
    "\n",
    "### 机器学习实施步骤\n",
    "\n",
    "实现机器学习的一般步骤：\n",
    "\n",
    "1. 数据收集\n",
    "2. 数据准备\n",
    "3. 数据分析\n",
    "4. 训练算法\n",
    "5. 测试算法\n",
    "6. 应用算法\n",
    "\n",
    "### Scikit-learn介绍\n",
    "\n",
    "![](res/scikit-learn-logo.png)\n",
    "\n",
    "Scikit-learn源于Google Summer of Code项目，由David Cournapeau在2007年发起，它提供了机器学习可能用到的工具，包括数据预处理、监督学习（分类、回归）、非监督学习（聚类）、模型选择、降维等。\n",
    "\n",
    "官网地址：<https://scikit-learn.org/stable/index.html>\n",
    "\n",
    "安装方法：`pip install scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b9e307",
   "metadata": {},
   "source": [
    "## k最近邻分类\n",
    "\n",
    "$k$最近邻（简称kNN，k-Nearest Neighbor）是Cover和Hart在1968年提出的一种简单的监督学习算法，可用于字符识别、文本分类、图像识别等领域。kNN的工作机制非常简单：给定测试样本，基于某种距离度量（如：欧式距离、曼哈顿距离等）找出训练集中与其最接近的$k$个训练样本，然后基于这$k$个“最近邻居”的信息来进行预测。对于分类任务，可以在$k$个最近邻居中选择出现次数最多的类别标签作为预测的结果；对于回归任务，可以使用$k$个最近邻居实际输出（目标值）的平均值作为预测的结果，当然也可以根据距离的远近进行加权平均，距离越近的样本权重值就越大。\n",
    "\n",
    "### 案例：电影分类预测\n",
    "\n",
    "\n",
    "\n",
    "### k值的选择和交叉检验\n",
    "\n",
    "k值的选择对于kNN算法的结果有非常显著的影响。下面用李航博士的《统计学习方法》一书中的叙述，来对k值的选择加以说明。\n",
    "\n",
    "如果选择较小的$k$值，就相当于用较小的邻域中的训练实例进行预测，“学习”的近似误差会减小，只有与输入实例较近（相似的）训练实例才会对预测结果起作用；但缺点是“学习”的估计误差会增大，预测结果会对近邻的实例点非常敏感，如果近邻的实例点刚好是噪声，预测就会出错。换句话说，$k$值的减小就意味着整体模型变得复杂，容易发生**过拟合**。\n",
    "\n",
    "如果选择较大的$k$值，就相当于用较大的邻域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。这时候，与输入实例较远（不相似的）训练实例也会对预测起作用，使预测发生错误。对于$k=N$的极端情况（其中$N$代表所有的训练实例的数量），那么无论输入实例是什么，都会预测它属于训练实例中最多的类，很显然，这样的模型完全忽略了训练实例中大量的有用信息，是不可取的。\n",
    "\n",
    "实际应用中，$k$的取值通常都比较小，可以通过交叉检验的方式来选择较好的$k$值。\n",
    "\n",
    "\n",
    "\n",
    "### 算法优缺点\n",
    "\n",
    "优点：\n",
    "\n",
    "1. 简单有效\n",
    "2. 重新训练代价低\n",
    "3. 适合类域交叉样本\n",
    "4. 适合大样本分类\n",
    "\n",
    "缺点：\n",
    "\n",
    "1. 惰性学习\n",
    "2. 输出的可解释性不强\n",
    "3. 不擅长处理不均衡样本\n",
    "4. 计算量比较大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb05ceb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
